[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello! My name is Ayça ÇETİN. \nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more. \n\n\n\n Back to top"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Welcome to my project page.\nKeep an eye on this space to stay updated with my project activities."
  },
  {
    "objectID": "project.html#data-source",
    "href": "project.html#data-source",
    "title": "Project",
    "section": "2.1 Data Source",
    "text": "2.1 Data Source\n\nDeprem Senaryosu Analiz Sonuçları\n2017 Yılı Mahalle Bazlı Bina Sayıları\nVDYM İlçe Bazında Hanelerdeki Riskli Yapı Durumu Bireysel Öngörüleri\nVDYM İlçe Bazında Hanelerdeki Kentsel Dönüşüm Fikri Bireysel Öngörüleri\nİl Düzeyinde Bina ve Konut Niteliklerine Göre Hanehalkı Sayısı vs Binanın İnşa Yılı\nİl Düzeyinde Bina ve Konut Niteliklerine Göre Hanehalkı Sayısı vs Binanın Kat Sayısı\nİlçe Bazlı Ortalama Hane Halkı Büyüklüğü\n2019 Yılı Belediye Nüfusları\nİstanbul Çevresinde Gerçekleşen Depremler\n\nInformation and explanations about these datasets are included in the section 2.2 General Information About Data.\nAll this data was taken from İstanbul Büyükşehir Belediyesi Açık Veri Portalı and TÜİK Merkezi Dağıtım Sistemi.\n\n#install.packages(\"readxl\")\nlibrary(readxl)\n\ndeprem_senaryo&lt;-read_excel(\"/Users/aycacetin/Desktop/deprem.xlsx\", sheet=1)\nbina_sayi&lt;-read_excel(\"/Users/aycacetin/Desktop/deprem.xlsx\", sheet=2)\nriskli_yapi_durumu&lt;-read_excel(\"/Users/aycacetin/Desktop/deprem.xlsx\", sheet=3)\nkentsel_donusum_fikri&lt;-read_excel(\"/Users/aycacetin/Desktop/deprem.xlsx\", sheet=4)\ninsa_yilina_gore_hanehalki_sayisi&lt;-read_excel(\"/Users/aycacetin/Desktop/deprem.xlsx\", sheet=5)\nkat_sayisina_gore_hanehalki_sayisi&lt;-read_excel(\"/Users/aycacetin/Desktop/deprem.xlsx\", sheet=6)\nort_hane&lt;-read_excel(\"/Users/aycacetin/Desktop/deprem.xlsx\", sheet=7)\nbelediye_nüfus&lt;-read_excel(\"/Users/aycacetin/Desktop/deprem.xlsx\", sheet=8)\ngerceklesen_deprem&lt;-read_excel(\"/Users/aycacetin/Desktop/deprem.xlsx\", sheet=9)\n\nsave(deprem_senaryo, file=\"deprem_senaryo.RData\")\nsave(bina_sayi, file=\"bina_sayi.RData\")\nsave(riskli_yapi_durumu, file=\"riskli_yapi_durumu.RData\")\nsave(kentsel_donusum_fikri, file=\"kentsel_donusum_fikri.RData\")\nsave(insa_yilina_gore_hanehalki_sayisi, file=\"insa_yilina_gore_hanehalki_sayisi.RData\")\nsave(kat_sayisina_gore_hanehalki_sayisi, file=\"kat_sayisina_gore_hanehalki_sayisi.RData\")\nsave(ort_hane, file=\"ort_hane.RData\")\nsave(belediye_nüfus, file=\"belediye_nüfus.RData\")\nsave(gerceklesen_deprem, file=\"gerceklesen_deprem.RData\")"
  },
  {
    "objectID": "project.html#general-information-about-data",
    "href": "project.html#general-information-about-data",
    "title": "Project",
    "section": "2.2 General Information About Data",
    "text": "2.2 General Information About Data\nDeprem Senaryosu Analiz Sonuçları is a dataset containing the results of an analysis made on an earthquake scenario that is predicted to have a magnitude of 7.5. Each row represents a neighbourhood. The columns have information mainly about the number of buildings based on damage level, the number of people based on vital status and pipe damages.\n2017 Yılı Mahalle Bazlı Bina Sayıları is a dataset about the buildings. Each row represents a neighbourhood. The columns have information mainly about year of construction and number of floors of the buildings.\nVDYM İlçe Bazında Hanelerdeki Riskli Yapı Durumu Bireysel Öngörüleri is a dataset about the opinions of households about the risky building situation on a district basis.\nVDYM İlçe Bazında Hanelerdeki Kentsel Dönüşüm Fikri Bireysel Öngörüleri is a dataset about the opinions of households about the idea of urban transformation on a district basis.\nİl Düzeyinde Bina ve Konut Niteliklerine Göre Hanehalkı Sayısı vs Binanın İnşa Yılı consists of the total number of households based on the year of construction of the buildings.\nİl Düzeyinde Bina ve Konut Niteliklerine Göre Hanehalkı Sayısı vs Binanın Kat Sayısı consists of the total number of households based on the number of floors of the buildings.\nİlçe Bazlı Ortalama Hane Halkı Büyüklüğü is a dataset about the average household size on a district basis.\n2019 Yılı Belediye Nüfusları is a dataset about the population within the borders of each municipality.\nİstanbul Çevresinde Gerçekleşen Depremler is a dataset about the earthquakes around Istanbul within 1 year. Each row represents an earthquake. In the columns, there are details about the earthquakes."
  },
  {
    "objectID": "project.html#reason-of-choice",
    "href": "project.html#reason-of-choice",
    "title": "Project",
    "section": "2.3 Reason of Choice",
    "text": "2.3 Reason of Choice\nIstanbul is a city where the risk of earthquake is said to be very high, and it is predicted to cause significant loss of life and property. Almost every day, warnings from experts about the earthquake, which is estimated to be between 7.2 and 7.6 in magnitude, can be seen in news and newspapers. I decided to work on such a current topic, to inform people through comprehensive analysis, to make them more aware, and to encourage taking steps against this disaster to get through with minimal damage."
  },
  {
    "objectID": "project.html#preprocessing",
    "href": "project.html#preprocessing",
    "title": "Project",
    "section": "2.4 Preprocessing",
    "text": "2.4 Preprocessing\nThere are 9 datasets in “.csv”, “.xls” and “.xlsx” formats which were downloaded from the sources mentioned in the section 2.1 Data Source. All these datasets have been merged into the same Excel file called “deprem.xlsx” and organized for a better use in the analysis. Each dataset is placed on a different sheet. After that, spelling errors on each dataset were corrected via Excel. In other words, correction of wrong letters was done. Finally, the “deprem.xlsx” file was read and stored in .RData format using the code in the section 2.1 Data Source. The .RData file can be downloaded to review."
  },
  {
    "objectID": "project.html#exploratory-data-analysis",
    "href": "project.html#exploratory-data-analysis",
    "title": "Project",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#trend-analysis",
    "href": "project.html#trend-analysis",
    "title": "Project",
    "section": "3.2 Trend Analysis",
    "text": "3.2 Trend Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#model-fitting",
    "href": "project.html#model-fitting",
    "title": "Project",
    "section": "3.3 Model Fitting",
    "text": "3.3 Model Fitting\nxxxxxx"
  },
  {
    "objectID": "project.html#results",
    "href": "project.html#results",
    "title": "Project",
    "section": "3.4 Results",
    "text": "3.4 Results\nxxxxxx"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the Spring 2024 EMU660 Decision Making with Analytics course.\nPlease use left menu to navigate through my assignments.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nHacettepe University, Research Assistant, 2024"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nTURKSAT, Intern, 2021\nHAVELSAN, Intern, 2022"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/assignments/assignment-1.html",
    "href": "docs/assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nMy first assignment has two parts."
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Assignment 1\nMy first assignment has three parts:\n\n(a) a brief summary about “Veri Bilimi ve Endüstri Mühendisliği Üzerine Sohbetler - Baykal Hafızoğlu & Erdi Daşdemir”:\nBaykal Hafızoğlu is the guest of our lecturer Erdi Daşdemir’s talk about data science and industrial engineering. In the beginning of the talk Hafızoğlu defines himself as an OR Scientist and Optimization Scientist. He indicates that his job is to write and solve OR models (mathematical models).\nHafızoğlu starts with OR and indicates that the classic definition of OR has changed a lot in the past few years. It was about optimization and statistics. However, it’s more about artificial intelligence and machine learning nowadays. That’s why Hafızoğlu prefers to call OR “analytics”.\nIt is possible to divide analytics into four:\n1-Descriptive analytics: Deals with defining the problem.\n2-Diagnostic analytics: Deals with what the problem is and what the reasons are.\n3-Predictive analytics: Deals with the future.\n4-Prescriptive analytics: Deals with suggesting a solution.\nHe highlights that what students learn in undergrad is very precious and they should be aware of it. In the end of undergrad, students gain a good knowledge about analytics.\nLater in his speech, he talks about the lessons he learned from his own experiences. Firstly, he says that “All projects start with a clear problem definition.”. It means that even about the simplest thing he needs to deal with, the problem definition must be clear and concise. A good, compatible KPI (Key Performance Indicator) needs to be chosen in order to present the problem, interpret and explain it to the user. After that, a success criteria needs to be defined in order to understand whether we have achieved success or not.\nAnother lesson that he learned from his own experiences is the importance of deployment. He thinks delivering the model to the user is always better than keeping it in your computer. In this case, “How to deploy” and “where to deploy” are important questions.\nHafızoğlu highlights the importance of the user interface and early prototype. User satisfaction is the most important thing that’s why the user needs to be understood well. Without keeping the user waiting, early prototype must be delivered for an early feedback. The user should not struggle to understand the user interface. If the user has to put effort, it shows that the user interface is not good enough.\nIt’s very crucial for users to understand and own the model they will use. Because they wouldn’t want to use models they don’t understand. Therefore, we should be able to explain the analytical model we have established.\nIn the end, we need to show the solution’s effect mathematically and refer to the problem and KPIs. Conflicting KPIs need to be considered because there can be a trade-off between KPIs. When one thing gets better, another thing can get worse.\n\n\n(b) exploring statistical summaries with custom functions and loops:\n\ndata(mtcars)#mtcars dataset\n\ncustom_summary&lt;-function(cars){\n  mean_cars&lt;-mean(cars)\n  median_cars&lt;-median(cars)\n  standard_deviation_cars&lt;-sd(cars)\n  minimum_cars&lt;-min(cars)\n  maximum_cars&lt;-max(cars)\n  \n  result&lt;-c(\"mean\"=mean_cars,\n            \"median\"=median_cars,\n            \"standard deviation\"=standard_deviation_cars,\n            \"minimum\"=minimum_cars,\n            \"maximum\"=maximum_cars)\n  \n  return(result)\n}\n\ncars&lt;-c(1, 2, 3)#numeric vector\n\n#writing a custom summary function\nprint(\"writing a custom summary function\")\n\n[1] \"writing a custom summary function\"\n\nprint(\"mpg\")\n\n[1] \"mpg\"\n\ncustom_summary(mtcars$mpg[cars])\n\n              mean             median standard deviation            minimum \n          21.60000           21.00000            1.03923           21.00000 \n           maximum \n          22.80000 \n\nprint(\"cyl\")\n\n[1] \"cyl\"\n\ncustom_summary(mtcars$cyl[cars])\n\n              mean             median standard deviation            minimum \n          5.333333           6.000000           1.154701           4.000000 \n           maximum \n          6.000000 \n\nprint(\"disp\")\n\n[1] \"disp\"\n\ncustom_summary(mtcars$disp[cars])\n\n              mean             median standard deviation            minimum \n         142.66667          160.00000           30.02221          108.00000 \n           maximum \n         160.00000 \n\nprint(\"hp\")\n\n[1] \"hp\"\n\ncustom_summary(mtcars$hp[cars])\n\n              mean             median standard deviation            minimum \n        104.333333         110.000000           9.814955          93.000000 \n           maximum \n        110.000000 \n\nprint(\"drat\")\n\n[1] \"drat\"\n\ncustom_summary(mtcars$drat[cars])\n\n              mean             median standard deviation            minimum \n        3.88333333         3.90000000         0.02886751         3.85000000 \n           maximum \n        3.90000000 \n\nprint(\"wt\")\n\n[1] \"wt\"\n\ncustom_summary(mtcars$wt[cars])\n\n              mean             median standard deviation            minimum \n         2.6050000          2.6200000          0.2778039          2.3200000 \n           maximum \n         2.8750000 \n\nprint(\"qsec\")\n\n[1] \"qsec\"\n\ncustom_summary(mtcars$qsec[cars])\n\n              mean             median standard deviation            minimum \n         17.363333          17.020000           1.115362          16.460000 \n           maximum \n         18.610000 \n\nprint(\"vs\")\n\n[1] \"vs\"\n\ncustom_summary(mtcars$vs[cars])\n\n              mean             median standard deviation            minimum \n         0.3333333          0.0000000          0.5773503          0.0000000 \n           maximum \n         1.0000000 \n\nprint(\"am\")\n\n[1] \"am\"\n\ncustom_summary(mtcars$am[cars])\n\n              mean             median standard deviation            minimum \n                 1                  1                  0                  1 \n           maximum \n                 1 \n\nprint(\"gear\")\n\n[1] \"gear\"\n\ncustom_summary(mtcars$gear[cars])\n\n              mean             median standard deviation            minimum \n                 4                  4                  0                  4 \n           maximum \n                 4 \n\nprint(\"carb\")\n\n[1] \"carb\"\n\ncustom_summary(mtcars$carb[cars])\n\n              mean             median standard deviation            minimum \n          3.000000           4.000000           1.732051           1.000000 \n           maximum \n          4.000000 \n\n#applying the function using a loop\nprint(\"applying the function using a loop\")\n\n[1] \"applying the function using a loop\"\n\nfor(column_name in colnames(mtcars)){\n  column_data&lt;-mtcars[[column_name]][cars]\n  print(column_name)\n  print(custom_summary(column_data))\n}\n\n[1] \"mpg\"\n              mean             median standard deviation            minimum \n          21.60000           21.00000            1.03923           21.00000 \n           maximum \n          22.80000 \n[1] \"cyl\"\n              mean             median standard deviation            minimum \n          5.333333           6.000000           1.154701           4.000000 \n           maximum \n          6.000000 \n[1] \"disp\"\n              mean             median standard deviation            minimum \n         142.66667          160.00000           30.02221          108.00000 \n           maximum \n         160.00000 \n[1] \"hp\"\n              mean             median standard deviation            minimum \n        104.333333         110.000000           9.814955          93.000000 \n           maximum \n        110.000000 \n[1] \"drat\"\n              mean             median standard deviation            minimum \n        3.88333333         3.90000000         0.02886751         3.85000000 \n           maximum \n        3.90000000 \n[1] \"wt\"\n              mean             median standard deviation            minimum \n         2.6050000          2.6200000          0.2778039          2.3200000 \n           maximum \n         2.8750000 \n[1] \"qsec\"\n              mean             median standard deviation            minimum \n         17.363333          17.020000           1.115362          16.460000 \n           maximum \n         18.610000 \n[1] \"vs\"\n              mean             median standard deviation            minimum \n         0.3333333          0.0000000          0.5773503          0.0000000 \n           maximum \n         1.0000000 \n[1] \"am\"\n              mean             median standard deviation            minimum \n                 1                  1                  0                  1 \n           maximum \n                 1 \n[1] \"gear\"\n              mean             median standard deviation            minimum \n                 4                  4                  0                  4 \n           maximum \n                 4 \n[1] \"carb\"\n              mean             median standard deviation            minimum \n          3.000000           4.000000           1.732051           1.000000 \n           maximum \n          4.000000 \n\n#an alternative approach with apply\nprint(\"an alternative approach with apply\")\n\n[1] \"an alternative approach with apply\"\n\napply(mtcars[cars, ], 2, custom_summary)\n\n                        mpg      cyl      disp         hp       drat        wt\nmean               21.60000 5.333333 142.66667 104.333333 3.88333333 2.6050000\nmedian             21.00000 6.000000 160.00000 110.000000 3.90000000 2.6200000\nstandard deviation  1.03923 1.154701  30.02221   9.814955 0.02886751 0.2778039\nminimum            21.00000 4.000000 108.00000  93.000000 3.85000000 2.3200000\nmaximum            22.80000 6.000000 160.00000 110.000000 3.90000000 2.8750000\n                        qsec        vs am gear     carb\nmean               17.363333 0.3333333  1    4 3.000000\nmedian             17.020000 0.0000000  1    4 4.000000\nstandard deviation  1.115362 0.5773503  0    0 1.732051\nminimum            16.460000 0.0000000  1    4 1.000000\nmaximum            18.610000 1.0000000  1    4 4.000000\n\n\n\n\n(c) counting NA values and substituting with the number 660:\n\n#install.packages(\"dslabs\")\nlibrary(dslabs)\ndata(na_example)\n\n#total count of NA values\nsum(is.na(na_example))\n\n[1] 145\n\n#substituting the NA values with the number 660 and saving it as a new dataframe\nno_nas&lt;-ifelse(is.na(na_example), 660, na_example)\n\n#total count of NA values in the new dataframe\nsum(is.na(no_nas))\n\n[1] 0\n\ncount&lt;-0\n#total count of the number 660 in the new dataframe\nfor(i in 1:1000)\n  if(no_nas[i]==660)\n    count&lt;-count+1\ncount\n\n[1] 145\n\n\nDataset with NA values\n\n\n\n\n\nDataset with the number 660\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Assignment 2\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html#graduation-projects",
    "href": "about.html#graduation-projects",
    "title": "About Me",
    "section": "Graduation Projects",
    "text": "Graduation Projects\n\n“İş Atamalarının Çizelgeleme Yöntemi ile Eniyilenmesi”, MAN Türkiye A.Ş., 2022-2023"
  }
]